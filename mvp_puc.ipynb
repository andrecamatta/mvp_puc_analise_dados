{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdfe41a",
   "metadata": {},
   "source": [
    "# MVP Análise de Dados e Boas Práticas\n",
    "\n",
    "**Nome:** André Camatta\n",
    "\n",
    "**Dataset:** [Lending Club 2007-2020Q3](https://www.kaggle.com/datasets/ethon0426/lending-club-20072020q1?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c921ec2",
   "metadata": {},
   "source": [
    "## Descrição do problema\n",
    "\n",
    "### O problema\n",
    "\n",
    "Prever, no momento da concessão de um empréstimo peer-to-peer (P2P), se um empréstimo entrará em default (categorizado como Charged Off, Default ou > 60 dias de atraso) ou será liquidado normalmente (Fully Paid).\n",
    "Logo, queremos um modelo que mapeie atributos do tomador e das condições do empréstimo.\n",
    "\n",
    "Tipo de aprendizado: **Supervisionado – classificação binária**.\n",
    "\n",
    "### O que é peer-to-peer lending (P2P)?\n",
    "\n",
    "É um mercado eletrônico que conecta diretamente investidores e tomadores.\n",
    "\n",
    "O tomador solicita crédito numa “prateleira” on-line. A plataforma realiza scoring de risco e fixa taxa/prazo (ou leilão em alguns modelos). Diversos investidores financiam frações do empréstimo, diversificando risco. A plataforma cobra taxa de intermediação, mas não aporta recursos próprios — diferentemente de um banco tradicional que capta depósito e empresta em balanço.\n",
    "\n",
    "Nos EUA, a Lending Club e a Prosper iniciaram em 2006. Depois de 2020, a Lending Club comprou um banco regulado e passou a originar parte dos créditos no próprio balanço, mas o histórico 2007-2020 representa sua origem P2P.\n",
    "\n",
    "Estimar a probabilidade de inadimplência antes da originação é crítico para:\n",
    "\n",
    "(a) proteger o retorno dos investidores;\n",
    "\n",
    "(b) calibrar as taxas de juros ofertadas;\n",
    "\n",
    "(c) manter o nível de risco-carteira aceite pela plataforma e pelos reguladores.\n",
    "\n",
    "### Contexto de P2P lending no Brasil\n",
    "\n",
    "**Regulação vigente**  \n",
    "Desde a **Resolução CMN 4 656/2018**, o Banco Central passou a licenciar fintechs de crédito sob dois formatos:  \n",
    "* **SCD** – Sociedade de Crédito Direto (empresta recursos próprios)  \n",
    "* **SEP** – Sociedade de Empréstimo entre Pessoas (**modelo P2P**), que apenas intermedia tomadores e investidores por plataforma online. \n",
    "\n",
    "**Plataformas ativas (2025)**  \n",
    "Entre as SEPs mais conhecidas estão **Nexoos, Biva (PagBank), IOUU** e **Mutual**. A Nexoos, por exemplo, já originou **R$ 1,10 bilhão** em crédito para PMEs e conta com **≈ 122 mil investidores cadastrados**. \n",
    "\n",
    "**Tamanho de mercado e projeção**  \n",
    "Consultorias setoriais estimam que o **mercado brasileiro de P2P lending movimentou USD 5 bi em 2024** e pode atingir **USD 28,1 bi até 2033**, crescendo a **CAGR de 21 %**.\n",
    "\n",
    "**Fatores de crescimento**  \n",
    "* **Open Finance + Pix** reduzem custo de aquisição e verificações.  \n",
    "* Juros atrativos para investidores (geralmente **CDI + 8 pp a CDI + 30 pp** para PMEs) em comparação a renda fixa tradicional.  \n",
    "* Demanda de crédito por pequenas empresas que não conseguem limites suficientes nos bancos comerciais.  \n",
    "* Supervisão do BC aumenta a confiança, enquanto mantém exigências de segregação de contas e divulgação de risco. \n",
    "\n",
    "**Potencial**  \n",
    "Mesmo somando SCDs e SEPs, o estoque ainda representa **< 1 % da carteira total de crédito do SFN** — espaço amplo para consolidação e inovação, especialmente em nichos desatendidos (microcrédito, capital de giro regional). A combinação de **crescimento projetado de dois dígitos** e **barreiras regulatórias relativamente baixas** coloca o P2P como um dos segmentos fintech mais promissores na próxima década.\n",
    "\n",
    "\n",
    "**Fontes**\n",
    "- **Resolução CMN 4.656/2018** – cria as figuras SCD e SEP  \n",
    "  [PDF oficial – Banco Central](https://normativos.bcb.gov.br/Lists/Normativos/Attachments/50579/Res_4656_v7_L.pdf)\n",
    "\n",
    "- **Fintechs de crédito (FAQ do BC)** – visão geral sobre SCD e SEP  \n",
    "  [Banco Central – Página “Fintechs”](https://www.bcb.gov.br/estabilidadefinanceira/fintechs)\n",
    "\n",
    "- **Mercado brasileiro de P2P lending** – tamanho de USD 5 bi em 2024 e projeção de USD 28,1 bi em 2033 (CAGR 21 %)  \n",
    "  [IMARC Group – Brazil Peer-to-Peer Lending Market Report (2025)](https://www.imarcgroup.com/brazil-peer-to-peer-lending-market)\n",
    "\n",
    "- **Exemplo de plataforma SEP** – Nexoos atinge R$ 1 bi originados e 700 mil CNPJs analisados  \n",
    "  [Finsiders Brasil – “Nexoos volta a ter vida própria” (abr/2025)](https://finsidersbrasil.com.br/reportagem-exclusiva-fintechs/quatro-anos-apos-venda-para-fintech-da-americanas-nexoos-volta-a-ter-vida-propria/)\n",
    "\n",
    "### Conjunto de dados\n",
    "\n",
    "O conjunto de dados reúne todas as operações originadas pela Lending Club, maior plataforma norte-americana de peer-to-peer lending até 2020. A versão mais completa no Kaggle cobre de 2007 ao 3º tri/2020, com ≈ 2 milhões de empréstimos (≈ 1 GB) e ~145 colunas que descrevem perfil do tomador, condições da operação e evolução do pagamento.\n",
    "\n",
    "### Atributos-chave mais relevantes\n",
    "\n",
    "| Atributo                | Tipo original      | Papel previsto / Observação                                                  |\n",
    "|-------------------------|--------------------|------------------------------------------------------------------------------|\n",
    "| grade               | Categórico ordinal | Rating interno A–G (quanto mais perto de A, menor o risco)                   |\n",
    "| sub_grade           | Categórico ordinal | Faixa fina dentro do grade (A1–G5)                                           |\n",
    "| fico_range_low      | Numérico inteiro   | Limite inferior da faixa FICO na originação                                  |\n",
    "| fico_range_high     | Numérico inteiro   | Limite superior da faixa FICO                                                |\n",
    "| loan_amnt               | Numérico contínuo  | Valor solicitado pelo tomador                                                |\n",
    "| funded_amnt            | Numérico contínuo  | Valor efetivamente financiado pela plataforma                                |\n",
    "| int_rate               | Numérico (%)       | Taxa anual de juros do contrato                                              |\n",
    "| installment            | Numérico           | Parcela mensal estimada                                                      |\n",
    "| term                   | Categórico texto   | Prazo (36 ou 60 meses) — converter para 36/60 numérico                       |\n",
    "| emp_length             | Categórico texto   | Tempo de emprego; normalizar para 0–10 anos                                  |\n",
    "| home_ownership         | Categórico texto   | Situação de moradia (RENT, OWN, MORTGAGE etc.)                               |\n",
    "| annual_inc             | Numérico           | Renda anual declarada                                                        |\n",
    "| dti                    | Numérico           | *Debt-to-Income* ratio (%)                                                   |\n",
    "| issue_d                | String data        | Data de originação; converter para `datetime`                                |\n",
    "| earliest_cr_line       | String data        | Data da 1ª linha de crédito; usar para “histórico de crédito (anos)”         |\n",
    "| addr_state             | Categórico texto   | UF de residência — proxy de região econômica                                 |\n",
    "| verification_status    | Categórico texto   | Nível de verificação de renda (Verified, Source Verified, Not Verified)      |\n",
    "| purpose                | Categórico texto   | Finalidade declarada do empréstimo                                           |\n",
    "| application_type       | Categórico texto   | Tipo de aplicação (Individual / Joint)                                       |\n",
    "| loan_status            | Categórico texto   | Variável-alvo original (*Fully Paid*, *Charged Off* etc.)                    |\n",
    "| **target_default**     | Binário (criado)   | 1 = default / 0 = pago — rótulo para modelagem                               |\n",
    "\n",
    "### Restrições e condições para seleção dos dados\n",
    "\n",
    "- **Período analisado**  \n",
    "  Filtrar apenas empréstimos emitidos **entre 2015-01-01 e 2020-12-31** para manter um regime regulatório e macroeconômico homogêneo.\n",
    "\n",
    "- **Agregação do status do empréstimo**  \n",
    "  Consolidar `loan_status` em dois grupos:  \n",
    "  - `paid` → *Fully Paid*, *Does not meet the credit policy (Fully Paid)*  \n",
    "  - `default` → *Charged Off*, *Default*, *Late (31-120 days)*, *In Grace Period*, *Does not meet the credit policy (Charged Off)*, *Late (16-30 days)*  \n",
    "\n",
    "- **Prevenção de vazamento de informação futura**  \n",
    "  Remover colunas que só ficam conhecidas **depois** da concessão — p. ex. `last_pymnt_d`, `total_pymnt`, `recoveries`, `collection_recovery_fee`.\n",
    "\n",
    "- **Privacidade e conformidade**  \n",
    "  Excluir ou anonimizar identificadores diretos em dados ainda não ofuscados (`member_id`, `emp_title`, textos livres) mesmo que os dados sejam públicos, uma vez que eles serão republicados no github, tornando-me também responsável (LGPD).\n",
    "\n",
    "- **Limitações de recursos no Google Colab (requisito da avaliação)**  \n",
    "  - Ler o CSV em *chunks* (`chunksize = 100 000`) **ou**  \n",
    "  - Amostrar aleatoriamente até **≈ 400 000** linhas para experimentação interativa, mantendo a proporcionalidade das classes.\n",
    "\n",
    "- **Limite de tamanho de dataset a ser republicado no GitHub (requisito da avaliação)**  \n",
    "  O arquivo completo (≈ 393 MB compactado / > 1 GB descompactado) ultrapassa o limite de **100 MB por arquivo** imposto pelo GitHub. Para reprodutibilidade sem exceder cotas:  \n",
    "  1. Subir apenas uma **amostra ≤ 100 MB** no repositório. \n",
    "  2. **Git LFS** ou **Release Assets** para hospedar o arquivo completo.\n",
    "\n",
    "\n",
    "### Hipóteses\n",
    "\n",
    "- **Capacidade de pagamento influencia inadimplência**  \n",
    "   Métricas que refletem fluxo de caixa do tomador — p. ex. `dti` (*debt-to-income ratio*) e `annual_inc` — terão forte relação com a chance de **default**.\n",
    "\n",
    "- **FICO e *grades* internas concentram a maior parte da informação de risco**  \n",
    "   Variáveis como `grade`, `sub_grade`, `fico_range_low` e `fico_range_high` já incorporam modelos de *credit-scoring* do próprio Lending Club e devem ser preditores relevantes.\n",
    "\n",
    "- **Mudança de regime temporal**  \n",
    "   Empréstimos originados antes de 2015 (crise 2008 e período de expansão de crédito subsequente) podem ter distribuição de risco diferente dos emitidos em 2015-2020.\n",
    "\n",
    "- **Classes desbalanceadas**  \n",
    "   Espera-se que a proporção de empréstimos **pagos** seja bem maior que a de **inadimplentes** (≈ 80 % vs. 20 %), o que exigirá técnicas de balanceamento ou métricas adequadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77112b",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861e5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kaggle\n",
    "import zipfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd4c620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset anonimizado carregado do GitHub: (599994, 128)\n",
      "Amostra estratificada 2015-2020 (600k registros)\n",
      "Dados já anonimizados e filtrados conforme LGPD\n",
      "Processo documentado no Anexo A (final do notebook)\n",
      "\n",
      "Informações da amostra:\n",
      "   • Registros: 599,994\n",
      "   • Colunas: 128\n",
      "   • Período: 2015-2020\n",
      "   • Método: Amostragem estratificada por ano e target\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_end_date</th>\n",
       "      <th>payment_plan_start_date</th>\n",
       "      <th>hardship_length</th>\n",
       "      <th>hardship_dpd</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>orig_projected_additional_accrued_interest</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>target_default</th>\n",
       "      <th>ano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68619</td>\n",
       "      <td>77481190</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>17.27%</td>\n",
       "      <td>357.88</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31941</td>\n",
       "      <td>88514571</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>9.49%</td>\n",
       "      <td>587.92</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53611</td>\n",
       "      <td>78309085</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>16.29%</td>\n",
       "      <td>856.54</td>\n",
       "      <td>D</td>\n",
       "      <td>D1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11289</td>\n",
       "      <td>95149836</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>8.24%</td>\n",
       "      <td>86.48</td>\n",
       "      <td>B</td>\n",
       "      <td>B1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31928</td>\n",
       "      <td>94158449</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.49%</td>\n",
       "      <td>324.98</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0       68619  77481190    10000.0      10000.0          10000.0   36 months   \n",
       "1       31941  88514571    28000.0      28000.0          28000.0   60 months   \n",
       "2       53611  78309085    35000.0      35000.0          35000.0   60 months   \n",
       "3       11289  95149836     2750.0       2750.0           2750.0   36 months   \n",
       "4       31928  94158449    10000.0      10000.0          10000.0   36 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade  ... hardship_end_date  \\\n",
       "0   17.27%       357.88     D        D2  ...               NaN   \n",
       "1    9.49%       587.92     B        B2  ...               NaN   \n",
       "2   16.29%       856.54     D        D1  ...               NaN   \n",
       "3    8.24%        86.48     B        B1  ...               NaN   \n",
       "4   10.49%       324.98     B        B2  ...               NaN   \n",
       "\n",
       "  payment_plan_start_date  hardship_length hardship_dpd hardship_loan_status  \\\n",
       "0                     NaN              NaN          NaN                  NaN   \n",
       "1                     NaN              NaN          NaN                  NaN   \n",
       "2                     NaN              NaN          NaN                  NaN   \n",
       "3                     NaN              NaN          NaN                  NaN   \n",
       "4                     NaN              NaN          NaN                  NaN   \n",
       "\n",
       "  orig_projected_additional_accrued_interest hardship_payoff_balance_amount  \\\n",
       "0                                        NaN                            NaN   \n",
       "1                                        NaN                            NaN   \n",
       "2                                        NaN                            NaN   \n",
       "3                                        NaN                            NaN   \n",
       "4                                        NaN                            NaN   \n",
       "\n",
       "  hardship_last_payment_amount target_default   ano  \n",
       "0                          NaN              0  2016  \n",
       "1                          NaN              0  2016  \n",
       "2                          NaN              0  2016  \n",
       "3                          NaN              0  2016  \n",
       "4                          NaN              0  2016  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregamento de dados - Amostra estratificada do GitHub\n",
    "# Os dados foram pré-processados e anonimizados conforme documentado no Anexo A\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# URL do dataset anonimizado no GitHub\n",
    "github_url = \"https://raw.githubusercontent.com/andrecamatta/mvp_puc_analise_dados/master/lending_club_sample_2015_2020.csv.gz\"\n",
    "\n",
    "# Carregar diretamente do GitHub\n",
    "df = pd.read_csv(github_url, compression='gzip', low_memory=False)\n",
    "print(f\"Dataset anonimizado carregado do GitHub: {df.shape}\")\n",
    "print(\"Amostra estratificada 2015-2020 (600k registros)\")\n",
    "print(\"Dados já anonimizados e filtrados conforme LGPD\")\n",
    "print(\"Processo documentado no Anexo A (final do notebook)\")\n",
    "\n",
    "print(f\"\\nInformações da amostra:\")\n",
    "print(f\"   • Registros: {df.shape[0]:,}\")\n",
    "print(f\"   • Colunas: {df.shape[1]}\")\n",
    "print(f\"   • Período: 2015-2020\")\n",
    "print(f\"   • Método: Amostragem estratificada por ano e target\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e442ab",
   "metadata": {},
   "source": [
    "## Dados pré-processados e anonimizados\n",
    "\n",
    "### Sobre a amostra utilizada\n",
    "\n",
    "Os dados carregados acima são uma **amostra estratificada** já processada do dataset original Lending Club (2007-2020Q3). Esta amostra foi criada especificamente para:\n",
    "\n",
    "1. **Reprodutibilidade**: Permitir execução sem configuração da API e sem necessidade de disponibilidade do Kaggle\n",
    "2. **Conformidade**: Dados anonimizados seguindo princípios da LGPD  \n",
    "3. **Viabilidade técnica**: Arquivo <100MB compatível com repositórios GitHub\n",
    "4. **Representatividade**: Mantém distribuição temporal e de classes originais\n",
    "\n",
    "### Limitações técnicas endereçadas\n",
    "\n",
    "#### **Autenticação Kaggle**\n",
    "- Dataset original requer credenciais da API do Kaggle (`kaggle.json`)\n",
    "- Nem todos os avaliadores possuem conta/configuração\n",
    "- **Solução**: Amostra pré-processada disponível diretamente no GitHub\n",
    "\n",
    "#### **Limitações do github** \n",
    "- Arquivo original: ~1.7GB (incompatível com Git padrão)\n",
    "- Limite GitHub: 100MB por arquivo\n",
    "- **Solução**: Amostragem estratificada mantendo representatividade\n",
    "\n",
    "### Garantias de qualidade da amostra\n",
    "\n",
    "**Amostragem estratificada** por ano E variável target \n",
    "**Preservação de proporções temporais** (2015-2020)  \n",
    "**Manutenção da distribuição de classes** (default vs. pago)  \n",
    "**Anonimização completa** removendo identificadores pessoais e colunas de vazamento futuro\n",
    "\n",
    "O processo completo está documentado no **Anexo A** ao final deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aad53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informações do dataset carregado:\n",
      "Shape: (599994, 128)\n",
      "Período: 2015-01-01 a 2020-09-01\n",
      "\n",
      "Distribuição da variável target:\n",
      "   Pagos (0): 77.9%\n",
      "   Default (1): 22.1%\n",
      "\n",
      "Colunas principais (128 total):\n",
      "   - loan_amnt\n",
      "   - grade\n",
      "   - int_rate\n",
      "   - annual_inc\n",
      "   - dti\n",
      "   - fico_range_low\n",
      "   - target_default\n",
      "\n",
      "Distribuição temporal:\n",
      "   2015: 169,804 registros (28.3%)\n",
      "   2016: 170,097 registros (28.3%)\n",
      "   2017: 134,429 registros (22.4%)\n",
      "   2018: 87,003 registros (14.5%)\n",
      "   2019: 36,327 registros (6.1%)\n",
      "   2020: 2,334 registros (0.4%)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 599994 entries, 0 to 599993\n",
      "Columns: 128 entries, Unnamed: 0 to ano\n",
      "dtypes: datetime64[ns](1), float64(97), int32(1), int64(3), object(26)\n",
      "memory usage: 583.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Análise das características da amostra\n",
    "print(\"Informações do dataset carregado:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Período: {df['issue_d'].min()} a {df['issue_d'].max()}\")\n",
    "\n",
    "# Verificar se já tem a variável target\n",
    "if 'target_default' in df.columns:\n",
    "    print(f\"\\nDistribuição da variável target:\")\n",
    "    target_dist = df['target_default'].value_counts(normalize=True)\n",
    "    print(f\"   Pagos (0): {target_dist[0]:.1%}\")\n",
    "    print(f\"   Default (1): {target_dist[1]:.1%}\")\n",
    "else:\n",
    "    print(\"Variável target não encontrada - dataset precisa ser processado\")\n",
    "\n",
    "print(f\"\\nColunas principais ({len(df.columns)} total):\")\n",
    "key_columns = ['loan_amnt', 'grade', 'int_rate', 'annual_inc', 'dti', 'fico_range_low', 'target_default']\n",
    "existing_key_cols = [col for col in key_columns if col in df.columns]\n",
    "for col in existing_key_cols[:10]:  # Mostrar primeiras 10\n",
    "    print(f\"   - {col}\")\n",
    "if len(existing_key_cols) > 10:\n",
    "    print(f\"   ... e mais {len(existing_key_cols) - 10} colunas\")\n",
    "\n",
    "# Verificar distribuição temporal\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])  # Converter para datetime primeiro\n",
    "df['ano'] = df['issue_d'].dt.year\n",
    "print(f\"\\nDistribuição temporal:\")\n",
    "year_dist = df['ano'].value_counts().sort_index()\n",
    "for year, count in year_dist.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {year}: {count:,} registros ({pct:.1f}%)\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efc6f1",
   "metadata": {},
   "source": [
    "## Análise exploratória dos dados\n",
    "\n",
    "Agora que temos os dados carregados, vamos analisar suas características principais para entender o conjunto de dados e preparar para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ec0b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DISTRIBUIÇÃO DA VARIÁVEL TARGET\n",
      "==================================================\n",
      "Classe 0 (Pago):    467,554 (77.9%)\n",
      "Classe 1 (Default): 132,440 (22.1%)\n",
      "\n",
      "Razão de desbalanceamento: 3.5:1\n",
      "  Classes desbalanceadas - considerar técnicas de balanceamento\n",
      "\n",
      " DISTRIBUIÇÃO TEMPORAL\n",
      "==================================================\n",
      "2015: 169,804 ( 28.3%) █████████\n",
      "2016: 170,097 ( 28.3%) █████████\n",
      "2017: 134,429 ( 22.4%) ███████\n",
      "2018: 87,003 ( 14.5%) ████\n",
      "2019: 36,327 (  6.1%) ██\n",
      "2020:  2,334 (  0.4%) \n",
      "\n",
      "Período total: 2015-01-01 a 2020-09-01\n"
     ]
    }
   ],
   "source": [
    "# Análise da distribuição da variável target\n",
    "print(\" DISTRIBUIÇÃO DA VARIÁVEL TARGET\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'target_default' in df.columns:\n",
    "    target_counts = df['target_default'].value_counts()\n",
    "    target_pct = df['target_default'].value_counts(normalize=True)\n",
    "    \n",
    "    print(f\"Classe 0 (Pago):    {target_counts[0]:6,} ({target_pct[0]:.1%})\")\n",
    "    print(f\"Classe 1 (Default): {target_counts[1]:6,} ({target_pct[1]:.1%})\")\n",
    "    \n",
    "    # Verificar se há desbalanceamento\n",
    "    imbalance_ratio = target_counts[0] / target_counts[1]\n",
    "    print(f\"\\nRazão de desbalanceamento: {imbalance_ratio:.1f}:1\")\n",
    "    \n",
    "    if imbalance_ratio > 3:\n",
    "        print(\"  Classes desbalanceadas - considerar técnicas de balanceamento\")\n",
    "    else:\n",
    "        print(\" Classes relativamente balanceadas\")\n",
    "        \n",
    "else:\n",
    "    print(\" Variável target não encontrada\")\n",
    "\n",
    "print(f\"\\n DISTRIBUIÇÃO TEMPORAL\")\n",
    "print(\"=\"*50)\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "df['ano'] = df['issue_d'].dt.year\n",
    "\n",
    "year_counts = df['ano'].value_counts().sort_index()\n",
    "for year, count in year_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    bar = \"█\" * int(pct // 3)\n",
    "    print(f\"{year}: {count:6,} ({pct:5.1f}%) {bar}\")\n",
    "    \n",
    "print(f\"\\nPeríodo total: {df['issue_d'].min().date()} a {df['issue_d'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa56878",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ANEXO A - Pipeline de Anonimização e Amostragem Estratificada\n",
    "\n",
    "Este anexo documenta o processo completo de preparação dos dados utilizado para criar a amostra anonimizada carregada no notebook principal.\n",
    "\n",
    "### Objetivos do Pipeline\n",
    "\n",
    "1. **Download automatizado** do dataset original via API do Kaggle\n",
    "2. **Anonimização completa** removendo identificadores pessoais (LGPD)\n",
    "3. **Filtragem temporal** para período homogêneo (2015-2020)\n",
    "4. **Amostragem estratificada** mantendo representatividade\n",
    "5. **Compactação** para compatibilidade com GitHub (<100MB)\n",
    "\n",
    "### Módulo: `dataset_anonymization.py`\n",
    "\n",
    "O código abaixo foi modularizado no arquivo `dataset_anonymization.py` para facilitar manutenção e reutilização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1859a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline de anonimização documentado\n",
      " Para executar: descomente o código e configure kaggle.json\n",
      " Código completo disponível em: dataset_anonymization.py\n"
     ]
    }
   ],
   "source": [
    "# CÓDIGO DOCUMENTATIVO - Pipeline de Anonimização e Amostragem\n",
    "# Este código está comentado pois a amostra já foi processada\n",
    "# Para execução, descomente e configure kaggle.json\n",
    "\n",
    "'''\n",
    "# 1. Download do dataset original (requer configuração do Kaggle)\n",
    "import kaggle\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def download_kaggle_dataset(dataset_id='ethon0426/lending-club-20072020q1'):\n",
    "    \"\"\"Download do dataset do Kaggle via API\"\"\"\n",
    "    try:\n",
    "        kaggle.api.dataset_download_files(dataset_id, path='.', unzip=True)\n",
    "        print(f\" Dataset baixado: {dataset_id}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\" Erro no download: {e}\")\n",
    "        return False\n",
    "\n",
    "# 2. Carregamento do arquivo principal\n",
    "def load_lending_club_data():\n",
    "    \"\"\"Carrega o dataset principal do Lending Club\"\"\"\n",
    "    filename = 'Loan_status_2007-2020Q3.gzip'\n",
    "    \n",
    "    # O arquivo está em formato CSV, não gzip binário\n",
    "    df = pd.read_csv(filename, low_memory=False)\n",
    "    print(f\"Dataset original carregado: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# 3. Anonimização e filtragem\n",
    "def anonymize_and_filter_data(df):\n",
    "    \"\"\"\n",
    "    Aplica anonimização e filtros conforme LGPD e requisitos do projeto\n",
    "    \"\"\"\n",
    "    # Filtrar período 2015-2020\n",
    "    df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "    df_filtered = df[(df['issue_d'] >= '2015-01-01') & \n",
    "                     (df['issue_d'] <= '2020-12-31')].copy()\n",
    "    \n",
    "    # Criar variável target binária\n",
    "    paid_status = ['Fully Paid', 'Does not meet the credit policy. Status:Fully Paid']\n",
    "    default_status = ['Charged Off', 'Default', 'Late (31-120 days)', \n",
    "                     'In Grace Period', 'Does not meet the credit policy. Status:Charged Off', \n",
    "                     'Late (16-30 days)']\n",
    "    \n",
    "    df_filtered = df_filtered[df_filtered['loan_status'].isin(paid_status + default_status)]\n",
    "    df_filtered['target_default'] = df_filtered['loan_status'].isin(default_status).astype(int)\n",
    "    \n",
    "    # Remover colunas com vazamento de informação futura\n",
    "    future_leak_cols = ['last_pymnt_d', 'total_pymnt', 'recoveries', \n",
    "                       'collection_recovery_fee', 'last_credit_pull_d', \n",
    "                       'out_prncp', 'out_prncp_inv', 'total_pymnt_inv',\n",
    "                       'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', \n",
    "                       'hardship_flag', 'settlement_status', 'settlement_date', \n",
    "                       'settlement_amount', 'debt_settlement_flag']\n",
    "    \n",
    "    existing_leak_cols = [col for col in future_leak_cols if col in df_filtered.columns]\n",
    "    df_filtered = df_filtered.drop(columns=existing_leak_cols)\n",
    "    \n",
    "    # Remover identificadores pessoais (LGPD)\n",
    "    privacy_cols = ['member_id', 'emp_title', 'url', 'desc', 'title']\n",
    "    existing_privacy_cols = [col for col in privacy_cols if col in df_filtered.columns]\n",
    "    df_filtered = df_filtered.drop(columns=existing_privacy_cols)\n",
    "    \n",
    "    print(f\"Dados anonimizados: {df_filtered.shape}\")\n",
    "    return df_filtered\n",
    "'''\n",
    "\n",
    "print(\" Pipeline de anonimização documentado\")\n",
    "print(\" Para executar: descomente o código e configure kaggle.json\")\n",
    "print(\" Código completo disponível em: dataset_anonymization.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca36cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algoritmo de amostragem estratificada documentado\n",
      "Garante representatividade por ano E variável target\n",
      "Resultado: arquivo <100MB compatível com GitHub\n"
     ]
    }
   ],
   "source": [
    "# CÓDIGO DOCUMENTATIVO - Amostragem Estratificada\n",
    "\n",
    "'''\n",
    "def create_stratified_sample(df, target_sample_size=600000):\n",
    "    \"\"\"\n",
    "    Cria amostra estratificada por ano e variável target\n",
    "    Garante representatividade temporal e de classes\n",
    "    \"\"\"\n",
    "    # Criar estratos combinando ano e target\n",
    "    df['strata'] = df['ano'].astype(str) + '_' + df['target_default'].astype(str)\n",
    "    \n",
    "    # Calcular proporções dos estratos\n",
    "    strata_props = df['strata'].value_counts(normalize=True)\n",
    "    \n",
    "    # Calcular tamanhos das amostras por estrato\n",
    "    sample_sizes = (strata_props * target_sample_size).round().astype(int)\n",
    "    \n",
    "    # Ajustar para atingir exatamente o tamanho desejado\n",
    "    current_size = sample_sizes.sum()\n",
    "    if current_size != target_sample_size:\n",
    "        diff = target_sample_size - current_size\n",
    "        largest_stratum = sample_sizes.idxmax()\n",
    "        sample_sizes[largest_stratum] += diff\n",
    "    \n",
    "    # Amostrar de cada estrato\n",
    "    dfs_sample = []\n",
    "    for strata, sample_size in sample_sizes.items():\n",
    "        if sample_size > 0:\n",
    "            strata_data = df[df['strata'] == strata]\n",
    "            \n",
    "            # Se o estrato tem menos dados que o necessário, pegar todos\n",
    "            if len(strata_data) <= sample_size:\n",
    "                sampled = strata_data\n",
    "            else:\n",
    "                sampled = strata_data.sample(n=sample_size, random_state=42)\n",
    "            dfs_sample.append(sampled)\n",
    "    \n",
    "    # Combinar todas as amostras\n",
    "    df_sample = pd.concat(dfs_sample, ignore_index=True)\n",
    "    df_sample = df_sample.drop(columns=['strata'])  # Remover coluna auxiliar\n",
    "    \n",
    "    print(f\"Amostra estratificada criada: {df_sample.shape}\")\n",
    "    print(f\"Taxa de amostragem: {len(df_sample)/len(df):.1%}\")\n",
    "    \n",
    "    return df_sample\n",
    "\n",
    "def save_sample_for_github(df_sample, filename='lending_club_sample_2015_2020.csv.gz'):\n",
    "    \"\"\"\n",
    "    Salva amostra compactada para upload no GitHub\n",
    "    \"\"\"\n",
    "    df_sample.to_csv(filename, compression='gzip', index=False)\n",
    "    \n",
    "    # Verificar tamanho do arquivo\n",
    "    file_size = os.path.getsize(filename) / (1024**2)  # MB\n",
    "    print(f\"Arquivo salvo: {filename}\")\n",
    "    print(f\"Tamanho: {file_size:.1f} MB\")\n",
    "    \n",
    "    if file_size < 100:\n",
    "        print(\"Compatível com GitHub (<100MB)\")\n",
    "    else:\n",
    "        print(\"Arquivo muito grande para GitHub\")\n",
    "    \n",
    "    return filename, file_size\n",
    "'''\n",
    "\n",
    "print(\"Algoritmo de amostragem estratificada documentado\")\n",
    "print(\"Garante representatividade por ano E variável target\")\n",
    "print(\"Resultado: arquivo <100MB compatível com GitHub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a5c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação de representatividade documentada\n",
      "Pipeline completo disponível em dataset_anonymization.py\n",
      "Para desenvolvedores: import dataset_anonymization; process_lending_club_pipeline()\n"
     ]
    }
   ],
   "source": [
    "# CÓDIGO DOCUMENTATIVO - Validação da Representatividade\n",
    "\n",
    "'''\n",
    "def analyze_temporal_distribution(df_original, df_sample):\n",
    "    \"\"\"\n",
    "    Analisa se a amostra mantém representatividade temporal\n",
    "    \"\"\"\n",
    "    # Distribuição por ano\n",
    "    original_years = df_original['ano'].value_counts(normalize=True).sort_index()\n",
    "    sample_years = df_sample['ano'].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    print(\"Comparação da distribuição temporal:\")\n",
    "    print(\"Ano | Original | Amostra  | Diferença\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for year in original_years.index:\n",
    "        orig_pct = original_years[year] * 100\n",
    "        samp_pct = sample_years.get(year, 0) * 100\n",
    "        diff = abs(orig_pct - samp_pct)\n",
    "        print(f\"{year} | {orig_pct:6.1f}% | {samp_pct:6.1f}% | {diff:6.1f}pp\")\n",
    "    \n",
    "    # Distribuição da variável target\n",
    "    orig_target = df_original['target_default'].value_counts(normalize=True)\n",
    "    samp_target = df_sample['target_default'].value_counts(normalize=True)\n",
    "    \n",
    "    print(f\"\\nDistribuição da variável target:\")\n",
    "    print(f\"Classe | Original | Amostra  | Diferença\")\n",
    "    print(\"-\" * 40)\n",
    "    for cls in [0, 1]:\n",
    "        orig_pct = orig_target[cls] * 100\n",
    "        samp_pct = samp_target[cls] * 100\n",
    "        diff = abs(orig_pct - samp_pct)\n",
    "        print(f\"   {cls}   | {orig_pct:6.1f}% | {samp_pct:6.1f}% | {diff:6.1f}pp\")\n",
    "\n",
    "# Pipeline completo\n",
    "def process_lending_club_pipeline(dataset_id='ethon0426/lending-club-20072020q1', \n",
    "                                 target_sample_size=600000):\n",
    "    \"\"\"\n",
    "    Pipeline completo: download → anonimização → amostragem → salvamento\n",
    "    \"\"\"\n",
    "    print(\"Iniciando pipeline completo...\")\n",
    "    \n",
    "    # 1. Download\n",
    "    if not download_kaggle_dataset(dataset_id):\n",
    "        return None, None\n",
    "    \n",
    "    # 2. Carregamento\n",
    "    df_original = load_lending_club_data()\n",
    "    \n",
    "    # 3. Anonimização\n",
    "    df_clean = anonymize_and_filter_data(df_original)\n",
    "    \n",
    "    # 4. Amostragem estratificada\n",
    "    df_sample = create_stratified_sample(df_clean, target_sample_size)\n",
    "    \n",
    "    # 5. Salvamento\n",
    "    filename, file_size = save_sample_for_github(df_sample)\n",
    "    \n",
    "    # 6. Validação\n",
    "    analyze_temporal_distribution(df_clean, df_sample)\n",
    "    \n",
    "    # Informações do processo\n",
    "    process_info = {\n",
    "        'original_shape': df_original.shape,\n",
    "        'filtered_shape': df_clean.shape,\n",
    "        'sample_shape': df_sample.shape,\n",
    "        'file_info': {'filename': filename, 'file_size_mb': file_size}\n",
    "    }\n",
    "    \n",
    "    print(\"Pipeline concluído com sucesso!\")\n",
    "    return df_sample, process_info\n",
    "'''\n",
    "\n",
    "print(\"Validação de representatividade documentada\")\n",
    "print(\"Pipeline completo disponível em dataset_anonymization.py\")\n",
    "print(\"Para desenvolvedores: import dataset_anonymization; process_lending_club_pipeline()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
